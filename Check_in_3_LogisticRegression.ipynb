{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHyapN/NfOeqGA1ZyS0Nlf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/rghosh1353/spotify_genre_proj/blob/main/Check_in_3_LogisticRegression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p60zKmOl_cZn",
        "outputId": "74f47902-8fe3-48bd-eef4-5a54e8d6f492"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting scikit-lego\n",
            "  Downloading scikit_lego-0.9.1-py2.py3-none-any.whl.metadata (12 kB)\n",
            "Collecting narwhals>=1.0.0 (from scikit-lego)\n",
            "  Downloading narwhals-1.10.0-py3-none-any.whl.metadata (7.0 kB)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.10/dist-packages (from scikit-lego) (2.2.2)\n",
            "Requirement already satisfied: scikit-learn>=1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-lego) (1.5.2)\n",
            "Requirement already satisfied: numpy>=1.22.4 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->scikit-lego) (1.26.4)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->scikit-lego) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->scikit-lego) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.1.5->scikit-lego) (2024.2)\n",
            "Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->scikit-lego) (1.13.1)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->scikit-lego) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=1.0->scikit-lego) (3.5.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas>=1.1.5->scikit-lego) (1.16.0)\n",
            "Downloading scikit_lego-0.9.1-py2.py3-none-any.whl (216 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m216.7/216.7 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading narwhals-1.10.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m10.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: narwhals, scikit-lego\n",
            "Successfully installed narwhals-1.10.0 scikit-lego-0.9.1\n"
          ]
        }
      ],
      "source": [
        "%pip install scikit-lego"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklego.linear_model import LADRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score"
      ],
      "metadata": {
        "id": "AmhNQ4tZ_zqp"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv(\"hf://datasets/maharshipandya/spotify-tracks-dataset/dataset.csv\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJF4Xpun_1J1",
        "outputId": "a1c5bb54-9e80-4515-94d9-72e14166bff4"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/utils/_token.py:89: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Data Cleaning Function\n",
        "def clean_data(df):\n",
        "  df = df.drop('Unnamed: 0', axis=1, errors='ignore')\n",
        "  df = df.dropna()\n",
        "  return df\n",
        "\n",
        "# Apply the function to the DataFrame\n",
        "spotify_clean = clean_data(df)"
      ],
      "metadata": {
        "id": "NMWOKL2v_14H"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_spotify, val_spotify = train_test_split(spotify_clean, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "NrA9K4EyACCB"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Stage 5: Logistic Regression"
      ],
      "metadata": {
        "id": "-Rbicaw7AGfi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Compute a Logistic Regression fit for the training dataset.\n"
      ],
      "metadata": {
        "id": "uCFpfRu6ADgV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5dXOOB-DAyC3"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}